{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3e1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be10f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('images_features_2d.pickle','rb') as features:\n",
    "\n",
    "    data=pickle.load(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c345cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 7, 1024)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CXR1_1_IM-0001-3001.png'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404204a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tags(image_id, tags):\n",
    "\n",
    "    new_tags=[]\n",
    "\n",
    "    for image in image_id.to_list():\n",
    "\n",
    "        tag=tags[image.split('_')[0]]\n",
    "\n",
    "        if tag[0].lower()=='normal':\n",
    "            new_tags.append('normal')\n",
    "        else:\n",
    "            new_tags.append('abnormal')\n",
    "\n",
    "    return new_tags\n",
    "\n",
    "path='/media/zaheer/Data/Image_Text_Datasets/IU_Xray/latest/One_Image_norm_abnorm_split/r2gen_annotations/'\n",
    "\n",
    "def read_r2gen_annotations():\n",
    "    with open(path+'annotation.json', 'rb') as f:\n",
    "        full_records = json.load(f)\n",
    "\n",
    "    splits=['train','val','test']\n",
    "    train=full_records['train']\n",
    "    val = full_records['val']\n",
    "    test = full_records['test']\n",
    "    \n",
    "    \n",
    "    new_records={}\n",
    "\n",
    "    for s in splits:\n",
    "        split_records = []\n",
    "        records=full_records[s]\n",
    "        for r in records:\n",
    "            tag=tags[r['id'].split('_')[0]]\n",
    "            if tag==0:\n",
    "                split_records.append(r)\n",
    "            else:\n",
    "                continue\n",
    "        new_records[s]=split_records\n",
    "\n",
    "with open(\"./data/iu_xray/annotation_10.json\", \"w\") as write_file:\n",
    "    json.dump(new_records, write_file)\n",
    "\n",
    "def load_preprocess_data():\n",
    "    tags = np.load('Data_with_tags.npy', allow_pickle=True).item()\n",
    "    train = pd.read_json(path+'/train/train.json')\n",
    "    #print(train.shape, train.columns)\n",
    "    x_train=train['image_id']\n",
    "\n",
    "    train_tags=fetch_tags(x_train,tags)\n",
    "    #print(train_tags)\n",
    "    #y_train = mlb.fit_transform([train_tags])\n",
    "    y_train=pd.get_dummies(train_tags)\n",
    "    #print(y_train)\n",
    "\n",
    "    #print(y_train.head())\n",
    "\n",
    "    test = pd.read_json(path+'/test/test.json')\n",
    "    x_test = test['image_id']\n",
    "\n",
    "    test_tags=fetch_tags(x_test,tags)\n",
    "    y_test = pd.get_dummies(test_tags)\n",
    "    \n",
    "    return x_train,y_train,x_test,y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ef96af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(split):\n",
    "    features = []#np.empty((0,7,7,1024))\n",
    "    \n",
    "    for image in split.tolist():\n",
    "        #print(image)\n",
    "        #features=np.hstack((features, data[image]))\n",
    "        #features=np.append(features, data[image], axis=0)\n",
    "        features.append(data[image])\n",
    "    features=np.array(features)\n",
    "    features=np.reshape(features,(-1,49,1024))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7c8305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_model(n):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(49,1024)))\n",
    "    \n",
    "    model.add(layers.GlobalAveragePooling1D())\n",
    "    #model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.05))\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(n, activation=\"sigmoid\"))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f905bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train,y_train,images_test,y_test=load_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf412a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=load_features(images_train)\n",
    "test_features=load_features(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1733cef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling1d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 65,730\n",
      "Trainable params: 65,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=class_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb2e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Train on 5068 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "5068/5068 [==============================] - 2s 324us/sample - loss: 0.6334 - precision: 0.6477 - recall: 0.6454 - val_loss: 0.5869 - val_precision: 0.6687 - val_recall: 0.6700\n",
      "Epoch 2/50\n",
      "5068/5068 [==============================] - 1s 174us/sample - loss: 0.5889 - precision: 0.6789 - recall: 0.6821 - val_loss: 0.5615 - val_precision: 0.6938 - val_recall: 0.7160\n",
      "Epoch 3/50\n",
      "5068/5068 [==============================] - 1s 177us/sample - loss: 0.5749 - precision: 0.6857 - recall: 0.6904 - val_loss: 0.5489 - val_precision: 0.7103 - val_recall: 0.7160\n",
      "Epoch 4/50\n",
      "5068/5068 [==============================] - 1s 173us/sample - loss: 0.5669 - precision: 0.6920 - recall: 0.6948 - val_loss: 0.5483 - val_precision: 0.7069 - val_recall: 0.7140\n",
      "Epoch 5/50\n",
      "5068/5068 [==============================] - 1s 173us/sample - loss: 0.5602 - precision: 0.6824 - recall: 0.6839 - val_loss: 0.5403 - val_precision: 0.7140 - val_recall: 0.7040\n",
      "Epoch 6/50\n",
      "5068/5068 [==============================] - 1s 174us/sample - loss: 0.5605 - precision: 0.7000 - recall: 0.6942 - val_loss: 0.5465 - val_precision: 0.7143 - val_recall: 0.6800\n",
      "Epoch 7/50\n",
      "5068/5068 [==============================] - 1s 172us/sample - loss: 0.5540 - precision: 0.7000 - recall: 0.6961 - val_loss: 0.5429 - val_precision: 0.6990 - val_recall: 0.6780\n",
      "Epoch 8/50\n",
      "5068/5068 [==============================] - 1s 176us/sample - loss: 0.5499 - precision: 0.7030 - recall: 0.7007 - val_loss: 0.5449 - val_precision: 0.7295 - val_recall: 0.7280\n",
      "Epoch 9/50\n",
      "5068/5068 [==============================] - 1s 173us/sample - loss: 0.5493 - precision: 0.7048 - recall: 0.7034 - val_loss: 0.5377 - val_precision: 0.7030 - val_recall: 0.6960\n",
      "Epoch 10/50\n",
      "5068/5068 [==============================] - 1s 171us/sample - loss: 0.5530 - precision: 0.6988 - recall: 0.6888 - val_loss: 0.5521 - val_precision: 0.7051 - val_recall: 0.6980\n",
      "Epoch 11/50\n",
      "5068/5068 [==============================] - 1s 155us/sample - loss: 0.5437 - precision: 0.7111 - recall: 0.6900 - val_loss: 0.5287 - val_precision: 0.7229 - val_recall: 0.7200\n",
      "Epoch 12/50\n",
      "5068/5068 [==============================] - 1s 157us/sample - loss: 0.5457 - precision: 0.7089 - recall: 0.6967 - val_loss: 0.5291 - val_precision: 0.7203 - val_recall: 0.7160\n",
      "Epoch 13/50\n",
      "5068/5068 [==============================] - 1s 153us/sample - loss: 0.5406 - precision: 0.7171 - recall: 0.7086 - val_loss: 0.5287 - val_precision: 0.7333 - val_recall: 0.7260\n",
      "Epoch 14/50\n",
      "5068/5068 [==============================] - 1s 155us/sample - loss: 0.5436 - precision: 0.7190 - recall: 0.7149 - val_loss: 0.5367 - val_precision: 0.7088 - val_recall: 0.7060\n",
      "Epoch 15/50\n",
      "5068/5068 [==============================] - 1s 155us/sample - loss: 0.5414 - precision: 0.7091 - recall: 0.7062 - val_loss: 0.5584 - val_precision: 0.7042 - val_recall: 0.7000\n",
      "Epoch 16/50\n",
      "5068/5068 [==============================] - 1s 224us/sample - loss: 0.5376 - precision: 0.7193 - recall: 0.7161 - val_loss: 0.5292 - val_precision: 0.7226 - val_recall: 0.7240\n",
      "Epoch 17/50\n",
      "5068/5068 [==============================] - 1s 182us/sample - loss: 0.5345 - precision: 0.7214 - recall: 0.7198 - val_loss: 0.5268 - val_precision: 0.7048 - val_recall: 0.7020\n",
      "Epoch 18/50\n",
      "5068/5068 [==============================] - 1s 184us/sample - loss: 0.5382 - precision: 0.7231 - recall: 0.7208 - val_loss: 0.5293 - val_precision: 0.7080 - val_recall: 0.7080\n",
      "Epoch 19/50\n",
      "5068/5068 [==============================] - 1s 182us/sample - loss: 0.5360 - precision: 0.7197 - recall: 0.7190 - val_loss: 0.5326 - val_precision: 0.7198 - val_recall: 0.7140\n",
      "Epoch 20/50\n",
      "5068/5068 [==============================] - 1s 185us/sample - loss: 0.5327 - precision: 0.7192 - recall: 0.7190 - val_loss: 0.5282 - val_precision: 0.7194 - val_recall: 0.7180\n",
      "Epoch 21/50\n",
      "5068/5068 [==============================] - 1s 182us/sample - loss: 0.5311 - precision: 0.7201 - recall: 0.7188 - val_loss: 0.5433 - val_precision: 0.7120 - val_recall: 0.7120\n",
      "Epoch 22/50\n",
      "5068/5068 [==============================] - 1s 183us/sample - loss: 0.5297 - precision: 0.7245 - recall: 0.7234 - val_loss: 0.5264 - val_precision: 0.7246 - val_recall: 0.7260\n",
      "Epoch 23/50\n",
      "5068/5068 [==============================] - 1s 184us/sample - loss: 0.5248 - precision: 0.7266 - recall: 0.7253 - val_loss: 0.5241 - val_precision: 0.7325 - val_recall: 0.7340\n",
      "Epoch 24/50\n",
      "5068/5068 [==============================] - 1s 183us/sample - loss: 0.5295 - precision: 0.7238 - recall: 0.7238 - val_loss: 0.5207 - val_precision: 0.7260 - val_recall: 0.7260\n",
      "Epoch 25/50\n",
      "5068/5068 [==============================] - 1s 184us/sample - loss: 0.5277 - precision: 0.7270 - recall: 0.7267 - val_loss: 0.5268 - val_precision: 0.7200 - val_recall: 0.7200\n",
      "Epoch 26/50\n",
      "5068/5068 [==============================] - 1s 183us/sample - loss: 0.5250 - precision: 0.7283 - recall: 0.7279 - val_loss: 0.5294 - val_precision: 0.7074 - val_recall: 0.7060\n",
      "Epoch 27/50\n",
      "5068/5068 [==============================] - 1s 219us/sample - loss: 0.5269 - precision: 0.7302 - recall: 0.7295 - val_loss: 0.5297 - val_precision: 0.7209 - val_recall: 0.7180\n",
      "Epoch 28/50\n",
      "5068/5068 [==============================] - 1s 181us/sample - loss: 0.5246 - precision: 0.7323 - recall: 0.7324 - val_loss: 0.5271 - val_precision: 0.7234 - val_recall: 0.7220\n",
      "Epoch 29/50\n",
      "5068/5068 [==============================] - 1s 173us/sample - loss: 0.5233 - precision: 0.7285 - recall: 0.7271 - val_loss: 0.5221 - val_precision: 0.7380 - val_recall: 0.7380\n",
      "Epoch 30/50\n",
      "5068/5068 [==============================] - 1s 174us/sample - loss: 0.5202 - precision: 0.7260 - recall: 0.7251 - val_loss: 0.5235 - val_precision: 0.7146 - val_recall: 0.7160\n",
      "Epoch 31/50\n",
      "5068/5068 [==============================] - 1s 172us/sample - loss: 0.5224 - precision: 0.7290 - recall: 0.7283 - val_loss: 0.5262 - val_precision: 0.7360 - val_recall: 0.7360\n",
      "Epoch 32/50\n",
      "5068/5068 [==============================] - 1s 178us/sample - loss: 0.5191 - precision: 0.7350 - recall: 0.7344 - val_loss: 0.5176 - val_precision: 0.7265 - val_recall: 0.7280\n",
      "Epoch 33/50\n",
      "5068/5068 [==============================] - 1s 175us/sample - loss: 0.5176 - precision: 0.7304 - recall: 0.7301 - val_loss: 0.5245 - val_precision: 0.7295 - val_recall: 0.7280\n",
      "Epoch 34/50\n",
      "5068/5068 [==============================] - 1s 216us/sample - loss: 0.5175 - precision: 0.7334 - recall: 0.7334 - val_loss: 0.5188 - val_precision: 0.7400 - val_recall: 0.7400\n",
      "Epoch 35/50\n",
      "5068/5068 [==============================] - 1s 179us/sample - loss: 0.5173 - precision: 0.7298 - recall: 0.7301 - val_loss: 0.5381 - val_precision: 0.7280 - val_recall: 0.7280\n",
      "Epoch 36/50\n",
      "5068/5068 [==============================] - 1s 181us/sample - loss: 0.5170 - precision: 0.7362 - recall: 0.7362 - val_loss: 0.5316 - val_precision: 0.7300 - val_recall: 0.7300\n",
      "Epoch 37/50\n",
      "5068/5068 [==============================] - 1s 211us/sample - loss: 0.5150 - precision: 0.7373 - recall: 0.7372 - val_loss: 0.5203 - val_precision: 0.7280 - val_recall: 0.7280\n",
      "Epoch 38/50\n",
      "5068/5068 [==============================] - 1s 201us/sample - loss: 0.5168 - precision: 0.7343 - recall: 0.7344 - val_loss: 0.5321 - val_precision: 0.7255 - val_recall: 0.7240\n",
      "Epoch 39/50\n",
      "5068/5068 [==============================] - 1s 208us/sample - loss: 0.5164 - precision: 0.7338 - recall: 0.7338 - val_loss: 0.5322 - val_precision: 0.7340 - val_recall: 0.7340\n",
      "Epoch 40/50\n",
      "5068/5068 [==============================] - 1s 212us/sample - loss: 0.5157 - precision: 0.7336 - recall: 0.7334 - val_loss: 0.5196 - val_precision: 0.7440 - val_recall: 0.7440\n",
      "Epoch 41/50\n",
      "5068/5068 [==============================] - 1s 204us/sample - loss: 0.5122 - precision: 0.7388 - recall: 0.7388 - val_loss: 0.5256 - val_precision: 0.7300 - val_recall: 0.7300\n",
      "Epoch 42/50\n",
      "5068/5068 [==============================] - 1s 198us/sample - loss: 0.5063 - precision: 0.7438 - recall: 0.7437 - val_loss: 0.5253 - val_precision: 0.7280 - val_recall: 0.7280\n",
      "Epoch 43/50\n",
      "5068/5068 [==============================] - 1s 193us/sample - loss: 0.5118 - precision: 0.7313 - recall: 0.7313 - val_loss: 0.5392 - val_precision: 0.7240 - val_recall: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "5068/5068 [==============================] - 1s 181us/sample - loss: 0.5066 - precision: 0.7382 - recall: 0.7382 - val_loss: 0.5301 - val_precision: 0.7220 - val_recall: 0.7220\n",
      "Epoch 45/50\n",
      "5068/5068 [==============================] - 1s 180us/sample - loss: 0.5082 - precision: 0.7383 - recall: 0.7382 - val_loss: 0.5243 - val_precision: 0.7220 - val_recall: 0.7220\n",
      "Epoch 46/50\n",
      "5068/5068 [==============================] - 1s 185us/sample - loss: 0.5082 - precision: 0.7399 - recall: 0.7397 - val_loss: 0.5196 - val_precision: 0.7280 - val_recall: 0.7280\n",
      "Epoch 47/50\n",
      "5068/5068 [==============================] - 1s 181us/sample - loss: 0.5103 - precision: 0.7449 - recall: 0.7451 - val_loss: 0.5311 - val_precision: 0.7140 - val_recall: 0.7140\n",
      "Epoch 48/50\n",
      "5068/5068 [==============================] - 1s 185us/sample - loss: 0.5039 - precision: 0.7391 - recall: 0.7390 - val_loss: 0.5477 - val_precision: 0.7160 - val_recall: 0.7160\n",
      "Epoch 49/50\n",
      "5068/5068 [==============================] - 1s 192us/sample - loss: 0.5032 - precision: 0.7409 - recall: 0.7407 - val_loss: 0.5230 - val_precision: 0.7194 - val_recall: 0.7180\n",
      "Epoch 50/50\n",
      "5068/5068 [==============================] - 1s 180us/sample - loss: 0.5032 - precision: 0.7382 - recall: 0.7384 - val_loss: 0.5295 - val_precision: 0.7400 - val_recall: 0.7400\n"
     ]
    }
   ],
   "source": [
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=0, mode='min')\n",
    "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()\n",
    "])\n",
    "\n",
    "model.fit(train_features, y_train.to_numpy(), epochs=50, callbacks=[earlyStopping],validation_data=(test_features, y_test.to_numpy()), batch_size=16)\n",
    "\n",
    "test_tags=model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca74cfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6542553191489362\n",
      "     abnormal  normal\n",
      "0           1       0\n",
      "1           1       0\n",
      "2           1       0\n",
      "3           1       0\n",
      "4           0       1\n",
      "..        ...     ...\n",
      "495         1       0\n",
      "496         0       1\n",
      "497         0       1\n",
      "498         1       0\n",
      "499         1       0\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "true=np.array(y_test).argmax(axis=1)\n",
    "pred=test_tags.argmax(axis=1)\n",
    "# #print(sum(test_tags.argmax(axis=1)))\n",
    "# y_test=y_test.idxmax(axis=1)\n",
    "# print(y_test)\n",
    "print(f1_score(true,pred))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c16c0c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=tf.keras.metrics.Recall()\n",
    "pred=test_tags.argmax(axis=1)\n",
    "m.update_state(np.array(y_test),test_tags)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1aa30a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "all_tags={}\n",
    "\n",
    "for idx,image in enumerate(images_test.to_list()):\n",
    "    all_tags[image.split('_')[0]]=pred[idx]\n",
    "    \n",
    "train_true=np.array(y_train).argmax(axis=1)\n",
    "print(sum(pred))\n",
    "for idx,image in enumerate(images_train.to_list()):\n",
    "    all_tags[image.split('_')[0]]=train_true[idx]\n",
    "\n",
    "print(all_tags['CXR63'])\n",
    "with open(path+'binary_tags_chex.pkl','wb') as file:\n",
    "    pickle.dump(all_tags, file, protocol=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d28fee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
